{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f36c717f",
   "metadata": {},
   "source": [
    "# OpenDota Premium Ingestion (Colab)\n",
    "\n",
    "This notebook prepares a Colab runtime to ingest OpenDota premium matches, load them into Supabase, and export XML archives. It is designed to run end-to-end without modifying the repository source code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60300c20",
   "metadata": {},
   "source": [
    "## 1) Install dependencies\n",
    "\n",
    "Run this cell first when starting a new Colab session. It installs the core dependencies for the ingestion CLI, Supabase access, and XML export utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install --upgrade pip\n",
    "!pip -q install supabase python-dotenv pandas lxml rich google-colab google-auth google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af3be13",
   "metadata": {},
   "source": [
    "## 2) Configure secrets (OpenDota + Supabase)\n",
    "\n",
    "The block below prompts for sensitive values at runtime so they are not stored in the notebook:\n",
    "- `OPENDOTA_PREMIUM_KEY`: premium API token.\n",
    "- `SUPABASE_URL` and `SUPABASE_SERVICE_ROLE_KEY`: Supabase project URL and service role key.\n",
    "- `SUPABASE_STORAGE_BUCKET`: storage bucket for XML archives (create one beforehand in Supabase storage).\n",
    "\n",
    "The values are persisted in environment variables for downstream cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de75444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Prompt once per session (rerun if you need to change values)\n",
    "OPENDOTA_PREMIUM_KEY = getpass('Enter your OpenDota PREMIUM API key: ')\n",
    "SUPABASE_URL = getpass('Enter your Supabase URL: ')\n",
    "SUPABASE_SERVICE_ROLE_KEY = getpass('Enter your Supabase service role key: ')\n",
    "SUPABASE_STORAGE_BUCKET = getpass('Enter the Supabase storage bucket for XML exports: ')\n",
    "\n",
    "os.environ['OPENDOTA_PREMIUM_KEY'] = OPENDOTA_PREMIUM_KEY\n",
    "os.environ['SUPABASE_URL'] = SUPABASE_URL\n",
    "os.environ['SUPABASE_SERVICE_ROLE_KEY'] = SUPABASE_SERVICE_ROLE_KEY\n",
    "os.environ['SUPABASE_STORAGE_BUCKET'] = SUPABASE_STORAGE_BUCKET\n",
    "print('✅ Secrets loaded into environment variables.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9e1b5",
   "metadata": {},
   "source": [
    "## 3) Run the ingestion CLI\n",
    "\n",
    "This section assumes the repository has an ingestion CLI entry point capable of pulling premium matches from OpenDota and writing them into Supabase. Update `INGESTION_CLI` to the correct script/module if it differs in your fork.\n",
    "\n",
    "The example below passes the premium key along with Supabase credentials so the CLI can write directly to your database and optionally push binary assets to storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# Adjust the path/module below to match your ingestion entry point\n",
    "# Example: Path('/content/Msc-Prometheus/03_INFRAESTRUTURA/opendota_ingest.py')\n",
    "INGESTION_CLI = Path('/content/Msc-Prometheus/opendota_ingest.py')\n",
    "\n",
    "if not INGESTION_CLI.exists():\n",
    "    raise FileNotFoundError(f'Update INGESTION_CLI to your ingestion script. Not found: {INGESTION_CLI}')\n",
    "\n",
    "base_env = os.environ.copy()\n",
    "base_env.update({\n",
    "    'OPENDOTA_PREMIUM_KEY': os.environ['OPENDOTA_PREMIUM_KEY'],\n",
    "    'SUPABASE_URL': os.environ['SUPABASE_URL'],\n",
    "    'SUPABASE_SERVICE_ROLE_KEY': os.environ['SUPABASE_SERVICE_ROLE_KEY'],\n",
    "    'SUPABASE_STORAGE_BUCKET': os.environ['SUPABASE_STORAGE_BUCKET'],\n",
    "})\n",
    "\n",
    "cli_cmd = [\n",
    "    sys.executable,\n",
    "    str(INGESTION_CLI),\n",
    "    '--api-key', base_env['OPENDOTA_PREMIUM_KEY'],\n",
    "    '--supabase-url', base_env['SUPABASE_URL'],\n",
    "    '--supabase-key', base_env['SUPABASE_SERVICE_ROLE_KEY'],\n",
    "    '--storage-bucket', base_env['SUPABASE_STORAGE_BUCKET'],\n",
    "    '--max-matches', '500',            # tweak as needed\n",
    "    '--min-match-id', '0',             # optionally resume from a specific match\n",
    "]\n",
    "\n",
    "print('Running ingestion CLI...')\n",
    "subprocess.run(cli_cmd, check=True, env=base_env)\n",
    "print('\n",
    "✅ Ingestion finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db58ce81",
   "metadata": {},
   "source": [
    "## 4) Verify Supabase row counts\n",
    "\n",
    "Use the Supabase Python client to confirm how many matches and players were ingested. Replace table names if your schema differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "\n",
    "supabase: Client = create_client(os.environ['SUPABASE_URL'], os.environ['SUPABASE_SERVICE_ROLE_KEY'])\n",
    "\n",
    "def table_count(table_name: str) -> int:\n",
    "    response = supabase.table(table_name).select('*', count='exact').limit(1).execute()\n",
    "    return response.count or 0\n",
    "\n",
    "match_count = table_count('matches')\n",
    "player_count = table_count('players')\n",
    "\n",
    "print(f\"Matches in Supabase: {match_count}\")\n",
    "print(f\"Players in Supabase: {player_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4820be2",
   "metadata": {},
   "source": [
    "## 5) Preview recent matches\n",
    "\n",
    "Pull a small sample of the most recent matches to validate the ingestion contents without downloading the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample = supabase.table('matches').select('*').order('match_id', desc=True).limit(5).execute()\n",
    "frame = pd.DataFrame(sample.data)\n",
    "\n",
    "print('Latest matches:')\n",
    "frame.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433120c",
   "metadata": {},
   "source": [
    "## 6) Export XML archives\n",
    "\n",
    "Create XML archives from the ingested matches and push them either to Colab Drive or directly into Supabase storage. The snippet writes `matches.xml` locally, mirrors it to Drive (if mounted), and uploads it to the configured bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41231cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "# Optional: mount Google Drive in Colab for a persistent copy\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    drive_path = Path('/content/drive/MyDrive/opendota')\n",
    "    drive_path.mkdir(parents=True, exist_ok=True)\n",
    "except ModuleNotFoundError:\n",
    "    drive_path = None\n",
    "    print('Running outside Colab; skipping Drive mount.')\n",
    "\n",
    "xml_path = Path('/content/matches.xml')\n",
    "xml_bucket_key = 'exports/matches.xml'\n",
    "\n",
    "xml_df = pd.DataFrame(frame) if 'frame' in locals() else pd.DataFrame(sample.data)\n",
    "xml_bytes = xml_df.to_xml(index=False).encode('utf-8')\n",
    "xml_path.write_bytes(xml_bytes)\n",
    "print(f'Saved XML locally to: {xml_path}')\n",
    "\n",
    "if drive_path:\n",
    "    drive_file = drive_path / 'matches.xml'\n",
    "    drive_file.write_bytes(xml_bytes)\n",
    "    print(f'Copied XML to Drive: {drive_file}')\n",
    "\n",
    "# Upload to Supabase storage\n",
    "storage = supabase.storage()\n",
    "upload_response = storage.from_(os.environ['SUPABASE_STORAGE_BUCKET']).upload(\n",
    "    file=BytesIO(xml_bytes),\n",
    "    path=xml_bucket_key,\n",
    "    file_options={'content-type': 'application/xml'}\n",
    ")\n",
    "print('Supabase storage upload response:')\n",
    "print(upload_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f580e31",
   "metadata": {},
   "source": [
    "## 7) (Optional) Download XML archive from storage\n",
    "\n",
    "If you need to verify the uploaded file, fetch it back from Supabase storage and inspect the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32327c",
   "metadata": {},
   "outputs": [],
   "source": [
    "download = storage.from_(os.environ['SUPABASE_STORAGE_BUCKET']).download(xml_bucket_key)\n",
    "roundtrip_df = pd.read_xml(BytesIO(download))\n",
    "roundtrip_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
